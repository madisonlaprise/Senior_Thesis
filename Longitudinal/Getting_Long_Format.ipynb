{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before dropping: ['Qualtricsname', 'Participant_Number', 'Corona', 'ResponseID', 'Worker_ID', 'StartDate', 'EndDate', 'Durationinseconds', 'Age', 'Gender', 'Education_version', 'Education_years_A', 'Relationship_status', 'Sexual_attraction', 'Children_YN', 'Children_num', 'Nationality', 'Ethnicity', 'LSAS_anx1', 'LSAS_anx2', 'LSAS_anx3', 'LSAS_anx4', 'LSAS_anx5', 'LSAS_anx6', 'LSAS_anx7', 'LSAS_anx8', 'LSAS_anx9', 'LSAS_anx10', 'LSAS_anx11', 'LSAS_anx12', 'LSAS_anx13', 'LSAS_anx14', 'LSAS_anx15', 'LSAS_anx16', 'LSAS_anx17', 'LSAS_anx18', 'LSAS_anx19', 'LSAS_anx20', 'LSAS_anx21', 'LSAS_anx22', 'LSAS_anx23', 'LSAS_anx24', 'LSAS_avo1', 'LSAS_avo2', 'LSAS_avo3', 'LSAS_avo4', 'LSAS_avo5', 'LSAS_avo6', 'LSAS_avo7', 'LSAS_avo8', 'LSAS_avo9', 'LSAS_avo10', 'LSAS_avo11', 'LSAS_avo12', 'LSAS_avo13', 'LSAS_avo14', 'LSAS_avo15', 'LSAS_avo16', 'LSAS_avo17', 'LSAS_avo18', 'LSAS_avo19', 'LSAS_avo20', 'LSAS_avo21', 'LSAS_avo22', 'LSAS_avo23', 'LSAS_avo24', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12', 'LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "Columns after dropping: ['Qualtricsname', 'Participant_Number', 'Corona', 'ResponseID', 'Worker_ID', 'StartDate', 'EndDate', 'Durationinseconds', 'Age', 'Gender', 'Education_version', 'Education_years_A', 'Relationship_status', 'Sexual_attraction', 'Children_YN', 'Children_num', 'Nationality', 'Ethnicity', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12', 'LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "LSAS columns: ['LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "Question columns for melt: ['LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12']\n",
      "   Participant_Number   StartDate                  EndDate Question  Score  \\\n",
      "0                 1.0  2019-06-30  2019-06-30 01:56:15.936   LSAS_1    1.0   \n",
      "1                 1.0  2019-07-03  2019-07-02 16:14:49.344   LSAS_1    0.0   \n",
      "2                 1.0  2019-07-09  2019-07-08 16:40:50.592   LSAS_1    0.0   \n",
      "3                 1.0  2019-09-26  2019-09-25 17:10:30.432   LSAS_1    0.0   \n",
      "4                 1.0  2019-09-26  2019-09-25 17:06:19.872   LSAS_1    3.0   \n",
      "\n",
      "   Standardized_Score  \n",
      "0            0.327492  \n",
      "1           -0.015907  \n",
      "2           -0.015907  \n",
      "3           -0.015907  \n",
      "4            1.014292  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 0: Load the data\n",
    "cleaned_data = pd.read_csv(r'C:\\Users\\MadiL\\Thesis CodeBase\\Longitudinal\\clean_data.csv')\n",
    "df = cleaned_data\n",
    "\n",
    "# Step 1: Combine LSAS_avo and LSAS_anx into LSAS_1, LSAS_2, ..., LSAS_24\n",
    "for i in range(1, 25):\n",
    "    avo_col = f'LSAS_avo{i}'\n",
    "    anx_col = f'LSAS_anx{i}'\n",
    "    combined_col = f'LSAS_{i}'\n",
    "    df[combined_col] = df[avo_col] + df[anx_col]\n",
    "\n",
    "# Step 2: Drop LSAS_avo_* and LSAS_anx_* columns\n",
    "cols_to_drop = [f'LSAS_avo{i}' for i in range(1, 25)] + [f'LSAS_anx{i}' for i in range(1, 25)]\n",
    "print(\"Columns before dropping:\", df.columns.tolist())\n",
    "df = df.drop(columns=cols_to_drop, errors='raise')  # Use 'raise' to ensure it fails if columns aren't found\n",
    "print(\"Columns after dropping:\", df.columns.tolist())\n",
    "\n",
    "# Step 3: Ensure only combined LSAS columns are used\n",
    "lsas_columns = [f'LSAS_{i}' for i in range(1, 25)]\n",
    "print(\"LSAS columns:\", lsas_columns)\n",
    "\n",
    "# Step 4: Define other question columns\n",
    "bdi_columns = [col for col in cleaned_data.columns if 'BDI' in col]\n",
    "cfs_columns = [col for col in cleaned_data.columns if 'CFS' in col]\n",
    "\n",
    "# Reverse score CFS questions 2, 3, 5, 10 in place\n",
    "reverse_columns = ['CFS2_R', 'CFS3_R', 'CFS5_R', 'CFS10_R']\n",
    "\n",
    "# Apply the reverse scoring transformation in place\n",
    "cleaned_data[reverse_columns] = 7 - cleaned_data[reverse_columns]\n",
    "\n",
    "# Reverse the DIRECTION of all CFS columns\n",
    "cleaned_data[cfs_columns] *= -1\n",
    "\n",
    "# Step 5: Combine all question columns into one list\n",
    "question_columns = lsas_columns + bdi_columns + cfs_columns\n",
    "print(\"Question columns for melt:\", question_columns)\n",
    "\n",
    "# Step 6: Reshape the data\n",
    "cleaned_data_sorted = cleaned_data.sort_values(by=['Participant_Number', 'StartDate'])\n",
    "long_data = pd.melt(cleaned_data_sorted, \n",
    "                    id_vars=['Participant_Number', 'StartDate', 'EndDate'], \n",
    "                    value_vars=question_columns, \n",
    "                    var_name='Question', value_name='Score')\n",
    "\n",
    "# Add standardized scores to the DataFrame while keeping the original 'Score' column\n",
    "# Ensure 'Score' has no missing values or non-numeric types\n",
    "long_data['Score'] = pd.to_numeric(long_data['Score'], errors='coerce').fillna(0)\n",
    "\n",
    "# Calculate standardized scores\n",
    "long_data['Standardized_Score'] = (long_data['Score'] - long_data['Score'].mean()) / long_data['Score'].std()\n",
    "\n",
    "# Verify the column was added\n",
    "print(long_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data\n",
    "\n",
    "# Save this from data wrangler, then make a long_data_standardized.csv where the standardized_score column is renamed to just score\n",
    "# Make another one, delete the standardized score column\n",
    "long_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
