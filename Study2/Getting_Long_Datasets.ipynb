{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before dropping: ['Qualtricsname', 'Participant_Number', 'Corona', 'ResponseID', 'Worker_ID', 'StartDate', 'EndDate', 'Durationinseconds', 'Age', 'Gender', 'Education_version', 'Education_years_A', 'Relationship_status', 'Sexual_attraction', 'Children_YN', 'Children_num', 'Nationality', 'Ethnicity', 'LSAS_anx1', 'LSAS_anx2', 'LSAS_anx3', 'LSAS_anx4', 'LSAS_anx5', 'LSAS_anx6', 'LSAS_anx7', 'LSAS_anx8', 'LSAS_anx9', 'LSAS_anx10', 'LSAS_anx11', 'LSAS_anx12', 'LSAS_anx13', 'LSAS_anx14', 'LSAS_anx15', 'LSAS_anx16', 'LSAS_anx17', 'LSAS_anx18', 'LSAS_anx19', 'LSAS_anx20', 'LSAS_anx21', 'LSAS_anx22', 'LSAS_anx23', 'LSAS_anx24', 'LSAS_avo1', 'LSAS_avo2', 'LSAS_avo3', 'LSAS_avo4', 'LSAS_avo5', 'LSAS_avo6', 'LSAS_avo7', 'LSAS_avo8', 'LSAS_avo9', 'LSAS_avo10', 'LSAS_avo11', 'LSAS_avo12', 'LSAS_avo13', 'LSAS_avo14', 'LSAS_avo15', 'LSAS_avo16', 'LSAS_avo17', 'LSAS_avo18', 'LSAS_avo19', 'LSAS_avo20', 'LSAS_avo21', 'LSAS_avo22', 'LSAS_avo23', 'LSAS_avo24', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12', 'YearMonth', 'LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "Columns after dropping: ['Qualtricsname', 'Participant_Number', 'Corona', 'ResponseID', 'Worker_ID', 'StartDate', 'EndDate', 'Durationinseconds', 'Age', 'Gender', 'Education_version', 'Education_years_A', 'Relationship_status', 'Sexual_attraction', 'Children_YN', 'Children_num', 'Nationality', 'Ethnicity', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12', 'YearMonth', 'LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "LSAS columns: ['LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24']\n",
      "Question columns for melt: ['LSAS_1', 'LSAS_2', 'LSAS_3', 'LSAS_4', 'LSAS_5', 'LSAS_6', 'LSAS_7', 'LSAS_8', 'LSAS_9', 'LSAS_10', 'LSAS_11', 'LSAS_12', 'LSAS_13', 'LSAS_14', 'LSAS_15', 'LSAS_16', 'LSAS_17', 'LSAS_18', 'LSAS_19', 'LSAS_20', 'LSAS_21', 'LSAS_22', 'LSAS_23', 'LSAS_24', 'BDI1', 'BDI2', 'BDI3', 'BDI4', 'BDI5', 'BDI6', 'BDI7', 'BDI8', 'BDI9', 'BDI10', 'BDI11', 'BDI12', 'BDI13', 'BDI14', 'BDI15', 'BDI16', 'BDI17', 'BDI18', 'BDI19', 'BDI20', 'CFS1', 'CFS2_R', 'CFS3_R', 'CFS4', 'CFS5_R', 'CFS6', 'CFS7', 'CFS8', 'CFS9', 'CFS10_R', 'CFS11', 'CFS12']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "cleaned_data = pd.read_csv(r'C:\\Users\\MadiL\\Thesis CodeBase\\Longitudinal\\Study2_data.csv')\n",
    "\n",
    "# Convert StartDate to datetime and extract Year-Month\n",
    "cleaned_data['StartDate'] = pd.to_datetime(cleaned_data['StartDate'])\n",
    "cleaned_data['YearMonth'] = cleaned_data['StartDate'].dt.to_period('M')\n",
    "\n",
    "# Combine LSAS_avo and LSAS_anx into LSAS_1, LSAS_2, ..., LSAS_24\n",
    "for i in range(1, 25):\n",
    "    avo_col = f'LSAS_avo{i}'\n",
    "    anx_col = f'LSAS_anx{i}'\n",
    "    combined_col = f'LSAS_{i}'\n",
    "    cleaned_data[combined_col] = cleaned_data[avo_col] + cleaned_data[anx_col]\n",
    "\n",
    "# Drop LSAS_avo_* and LSAS_anx_* columns\n",
    "cols_to_drop = [f'LSAS_avo{i}' for i in range(1, 25)] + [f'LSAS_anx{i}' for i in range(1, 25)]\n",
    "print(\"Columns before dropping:\", cleaned_data.columns.tolist())\n",
    "cleaned_data = cleaned_data.drop(columns=cols_to_drop, errors='raise')  # Use 'raise' to ensure it fails if columns aren't found\n",
    "print(\"Columns after dropping:\", cleaned_data.columns.tolist())\n",
    "\n",
    "# Ensure only combined LSAS columns are used\n",
    "lsas_columns = [f'LSAS_{i}' for i in range(1, 25)]\n",
    "print(\"LSAS columns:\", lsas_columns)\n",
    "\n",
    "# Define other question columns\n",
    "bdi_columns = [col for col in cleaned_data.columns if 'BDI' in col]\n",
    "cfs_columns = [col for col in cleaned_data.columns if 'CFS' in col]\n",
    "\n",
    "# Reverse score CFS questions 2, 3, 5, 10 in place\n",
    "reverse_columns = ['CFS2_R', 'CFS3_R', 'CFS5_R', 'CFS10_R']\n",
    "\n",
    "# Apply the reverse scoring transformation in place\n",
    "cleaned_data[reverse_columns] = 7 - cleaned_data[reverse_columns]\n",
    "\n",
    "# Reverse the DIRECTION of all CFS columns\n",
    "cleaned_data[cfs_columns] *= -1\n",
    "\n",
    "# Combine all question columns into one list\n",
    "question_columns = lsas_columns + bdi_columns + cfs_columns\n",
    "print(\"Question columns for melt:\", question_columns)\n",
    "\n",
    "# Reshape the data so that each row is a unique observation\n",
    "# Each row should have a Participant_Number, StartDate, EndDate, Question, and Score\n",
    "long_data = pd.melt(cleaned_data, \n",
    "                    id_vars=['Participant_Number', 'YearMonth'], \n",
    "                    value_vars=question_columns, \n",
    "                    var_name='Question', value_name='Score')\n",
    "\n",
    "# Aggregate observations within the same time point by the mean\n",
    "# Create a dictionary of unique participants for each time point\n",
    "participant_dict = long_data.groupby('YearMonth')['Participant_Number'].apply(set).to_dict()\n",
    "long_data= (\n",
    "    long_data.groupby(['Participant_Number', 'YearMonth', 'Question'])['Score']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Standardize\n",
    "long_data['Score'] = (long_data['Score'] - long_data['Score'].mean()) / long_data['Score'].std()\n",
    "\n",
    "df = long_data.copy()\n",
    "\n",
    "# Make a new dataframe for each time point\n",
    "df_1 = df[df['YearMonth'] == '2020-01']\n",
    "df_2 = df[df['YearMonth'] == '2020-05']\n",
    "df_3 = df[df['YearMonth'] == '2020-09']\n",
    "\n",
    "# Save the dataframes to csv files\n",
    "df_1.to_csv('df_1.csv', index=False)\n",
    "df_2.to_csv('df_2.csv', index=False)\n",
    "df_3.to_csv('df_3.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
